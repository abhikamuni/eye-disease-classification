{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6ca4d3-ee7a-4366-9454-2af6db4a09ef",
   "metadata": {},
   "source": [
    "Using EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b297c2f9-b140-4ce6-83a0-01c879de3914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.12.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\abhikamuni\\anaconda3\\Lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc102fd-5ff1-4148-8e09-f72f262d19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import time\n",
    "# import data handling tools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation, GlobalAveragePooling2D\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9354cd-ad35-443b-8eae-1b55c13fd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeDiseaseDataset:\n",
    "    def __init__(self, dataDir):\n",
    "        self.data_dir = dataDir\n",
    "   \n",
    "    def dataPaths(self):\n",
    "        filepaths = []\n",
    "        labels = []\n",
    "        folds = os.listdir(self.data_dir)\n",
    "        for fold in folds:\n",
    "            foldPath = os.path.join(self.data_dir, fold)\n",
    "            filelist = os.listdir(foldPath)\n",
    "            for file in filelist:\n",
    "                fpath = os.path.join(foldPath, file)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(fold)\n",
    "        return filepaths, labels\n",
    "  \n",
    "    def dataFrame(self, files, labels):\n",
    "\n",
    "        Fseries = pd.Series(files, name='filepaths')\n",
    "        Lseries = pd.Series(labels, name='labels')\n",
    "        return pd.concat([Fseries, Lseries], axis=1)\n",
    "   \n",
    "    def split_(self):\n",
    "        files, labels = self.dataPaths()\n",
    "        df = self.dataFrame(files, labels)\n",
    "        strat = df['labels']\n",
    "        trainData, dummyData = train_test_split(df, train_size=0.8, shuffle=True, random_state=42, stratify=strat)\n",
    "        strat = dummyData['labels']\n",
    "        validData, testData = train_test_split(dummyData, train_size=0.5, shuffle=True, random_state=42, stratify=strat)\n",
    "        return trainData, validData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bd954-822f-49e0-b734-5a34faad3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=r'C:\\Users\\abhikamuni\\Downloads\\Project\\eye-diseases-classification\\dataset'\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d327e7-5b3f-4e87-976f-befcc5ff1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSplit = EyeDiseaseDataset(dataDir)\n",
    "train_data, valid_data, test_data = dataSplit.split_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb43d1-f2f1-4448-9e74-ff9b0d8034a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_image(df):\n",
    "    random_row = df.sample(1).iloc[0]\n",
    "    filepath = random_row['filepaths']\n",
    "    label = random_row['labels']\n",
    "    \n",
    "    img = Image.open(filepath)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Label:{label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_random_image(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8abbc-1219-4cbf-b315-d01a82189597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data( train_df, valid_df, test_df, batch_size=16):\n",
    "\n",
    "    img_size = (256,256)\n",
    "    channels = 3\n",
    "    color = 'rgb'\n",
    "    \n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "              rotation_range=30,\n",
    "              horizontal_flip=True,\n",
    "              vertical_flip=True,\n",
    "              brightness_range=[0.5, 1.5])\n",
    "          \n",
    "    valid_test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "          \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "              train_df,\n",
    "              x_col='filepaths',\n",
    "              y_col='labels',\n",
    "              target_size=img_size,\n",
    "              color_mode=color,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              class_mode='categorical'\n",
    "          )\n",
    "   \n",
    "    print(\"Shape of augmented training images:\", train_generator.image_shape)\n",
    "          \n",
    "    valid_generator = valid_test_datagen.flow_from_dataframe(\n",
    "              valid_df,\n",
    "              x_col='filepaths',\n",
    "              y_col='labels',\n",
    "              target_size=img_size,\n",
    "              color_mode=color,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              class_mode='categorical'\n",
    "          )\n",
    "         \n",
    "    print(\"Shape of validation images:\", valid_generator.image_shape)\n",
    "          \n",
    "    test_generator = valid_test_datagen.flow_from_dataframe(\n",
    "              test_df,\n",
    "              x_col='filepaths',\n",
    "              y_col='labels',\n",
    "              target_size=img_size,\n",
    "              color_mode=color,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              class_mode='categorical'\n",
    "          )\n",
    "          \n",
    "    print(\"Shape of test images:\", test_generator.image_shape)\n",
    "          \n",
    "    return train_generator, valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a912566-2355-4e30-933b-998e35a99514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented, valid_augmented, test_augmented = augment_data(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bab17-7077-4ebc-ba20-38c9e7ca0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(gen):\n",
    "      \n",
    "    g_dict = gen.class_indices        # defines dictionary {'class': index}\n",
    "    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n",
    "    images, labels = next(gen)        # get a batch size samples from the generator\n",
    "    length = len(labels)       \n",
    "    sample = min(length, 20)   \n",
    "    plt.figure(figsize= (15, 17))\n",
    "    for i in range(sample):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image = images[i] / 255      \n",
    "        plt.imshow(image)\n",
    "        index = np.argmax(labels[i])  \n",
    "        class_name = classes[index]  \n",
    "        plt.title(class_name, color= 'blue', fontsize= 7 )\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "show_images(train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53936d8a-3dd5-40f1-a950-db744d4eeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "classes = len(list(train_augmented.class_indices.keys()))\n",
    "\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu' , kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "\n",
    "predictions = Dense(classes, activation='softmax', kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8300c8-eabb-48da-a981-75209ea4ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_augmented,\n",
    "    epochs=15, \n",
    "    validation_data=valid_augmented,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3c1cb-605f-43f9-94b7-40c8386a617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "print(\"Training Accuracy:\", train_accuracy[-1])\n",
    "print(\"Validation Accuracy:\", val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e1896-2344-4abc-a032-6bf294b982a0",
   "metadata": {},
   "source": [
    "#Using Densenet121 and rmsprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362cca4-d8b3-4d47-a839-0b3492c0709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(11) \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import backend as K \n",
    "import random\n",
    "import urllib.request\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from skimage.filters import rank, threshold_otsu\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files   \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from skimage.morphology import closing, square, disk\n",
    "#to see full text:\n",
    "pd.set_option(\"display.max_colwidth\", 1)\n",
    "from termcolor import colored\n",
    "print(colored(\"\\nNECESSARY LIBRARIES WERE SUCCESFULLY IMPORTED...\", color = \"green\", attrs = [\"bold\", \"dark\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadd5d5-071d-4f27-b7df-27f8990fa2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_train = os.listdir('C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset')\n",
    "print (dataset_path_train)\n",
    "print(\"Types of classes labels found: \", len(dataset_path_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b567ce-c020-4411-93f1-1c293bceec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "\n",
    "for item in dataset_path_train: \n",
    " #\n",
    " all_classes = os.listdir('C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset\\\\' + '/' +item+'/')\n",
    " # Add them to the list\n",
    " for room in all_classes:\n",
    "    class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c57ac3-f732-40f8-872d-4457eba32027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c456a8-62a4-47df-922c-e5bf827e7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Parameter we can use it in the network and model\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a572a8-46b3-4903-81c9-c894dad96760",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f912d-91b9-4092-97d7-243b934205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train data set\n",
    "train_ds = image_dataset_from_directory(data_dir, \n",
    "                                        seed = 123, \n",
    "                                        image_size=(img_height, img_width), \n",
    "                                        validation_split=0.2, \n",
    "                                        subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f987b-3073-4308-9960-54e981c39837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can put the validate data\n",
    "val_ds = image_dataset_from_directory(data_dir, \n",
    "                                      seed = 123, \n",
    "                                      image_size=(img_height, img_width), \n",
    "                                      validation_split=0.2, \n",
    "                                      subset='validation',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2ecbe-f7ba-4cdd-9565-9c6f94f4118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256,256,3)\n",
    "batch_size=64\n",
    "classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41527f-1fea-4a76-8cd2-574c66d7f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "dense = DenseNet121(weights = \"imagenet\", include_top = False, input_shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc589963-146a-4f2f-8caf-95890e86cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in dense.layers[:121]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ff384-4e5d-4345-a40d-64f42e8cd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(dense)\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation= \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e653da-5e1a-49fb-bebf-f2b2d05a7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bed62d-739b-45c1-9ed4-e1847cca0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 1\n",
    "stop_patience = 3\n",
    "factor = 0.5\n",
    "#tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"densenet121.h5\", save_best_only=True, verbose = 0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cf2fb-d73a-47cd-b9bc-1e4846364a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "plot_model(model, to_file='cnn-densenet-rmsprop-plant.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2b478-d444-48f0-8b65-a9318963f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 10, verbose = 1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d17a03-24cb-482b-bbf0-d1f1c2d42bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "print(\"Training Accuracy:\", train_accuracy[-1])\n",
    "print(\"Validation Accuracy:\", val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf633e-4f19-46ed-b8c5-ddb841d64037",
   "metadata": {},
   "source": [
    "#Using Densenet121 and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5a857-a133-4128-a3bb-1835b1fdac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(dense)\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation= \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ceb83-ff7d-4ff7-892e-01047ccd13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3b8f0-19c6-46eb-9a5a-987b00a78de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 1\n",
    "stop_patience = 3\n",
    "factor = 0.5\n",
    "#tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"densenet121.h5\", save_best_only=True, verbose = 0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37d5f3-054c-4e64-bc27-570116b0620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "plot_model(model, to_file='cnn-densenet-adam-plant.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda3192-f6f1-42af-8c26-6def0ee46138",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 10, verbose = 1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650401c-c96e-4346-8a57-337c3b0b6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "print(\"Training Accuracy:\", train_accuracy[-1])\n",
    "print(\"Validation Accuracy:\", val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240888e4-ad25-438a-a705-984b5f70d001",
   "metadata": {},
   "source": [
    "#cnn(DenseNet121) and rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc6878-218c-423e-ac8b-85b382db8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(11) # It's my lucky number\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import backend as K \n",
    "import random\n",
    "import urllib.request\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization, LSTM, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0  # Import EfficientNet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "\n",
    "from skimage.filters import rank, threshold_otsu\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files   \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from skimage.morphology import closing, square, disk\n",
    "#to see full text:\n",
    "pd.set_option(\"display.max_colwidth\", 1)\n",
    "from termcolor import colored\n",
    "print(colored(\"\\nNECESSARY LIBRARIES WERE SUCCESFULLY IMPORTED...\", color = \"green\", attrs = [\"bold\", \"dark\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4357961-8de4-4da8-b9a4-be537e153084",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_train = os.listdir('C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset')\n",
    "print (dataset_path_train)\n",
    "print(\"Types of classes labels found: \", len(dataset_path_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051bd4e7-dae9-48a7-82d0-f01cd12730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = []\n",
    "\n",
    "for item in dataset_path_train: \n",
    " #\n",
    " all_classes = os.listdir('C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset\\\\' + '\\\\' +item+'\\\\')\n",
    " # Add them to the list\n",
    " for room in all_classes:\n",
    "    class_label.append((item, str('C:\\\\Users\\\\abhikamuni\\\\Downloads\\\\Project\\\\eye-diseases-classification\\\\dataset\\\\' + item) + '\\\\' + room))\n",
    "\n",
    "\n",
    "# Extracting labels and file paths into separate lists\n",
    "labels = [label for label, _ in class_label]\n",
    "file_paths = [file_path for _, file_path in class_label]\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame({'Labels': labels, 'image': file_paths})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ed861-9db9-48c0-b46d-58c8fc7685df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Parameter we can use it in the network and model\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75908219-cc68-4aa2-8955-484c283ffa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[\"image\"], df[\"Labels\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d229bf6-4480-4d7e-b5da-6df40e644c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# One-hot encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train_encoded, num_classes)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val_encoded, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a9b18-4b63-44b8-957b-944e51725ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "\n",
    "# Load images and convert them to arrays\n",
    "def load_images(image_paths, img_height=256, img_width=256):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "X_train_cnn = load_images(X_train)\n",
    "X_val_cnn = load_images(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f3f05-3f99-4679-9660-6afe3107805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training Set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c8b1e-71da-444a-8b8b-663aa04c91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='image',\n",
    "    y_col='Labels',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbaf72-ba4c-4f01-a811-7656202314e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256,256,3)\n",
    "batch_size=64\n",
    "classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940751a0-f186-4ccd-ad5e-20ae2b620c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Load DenseNet121 model\n",
    "densenet = tf.keras.applications.DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737dc37-d8aa-4be8-ac07-0abe3b070f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "for layer in densenet.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87ec5c-145b-402d-8587-5723cfa8d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "cnn_output = densenet.output\n",
    "cnn_output = Flatten()(cnn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8b156-0d15-4a41-b4d3-69081f782ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM, Reshape\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, LSTM, Reshape, concatenate\n",
    "\n",
    "# Define the RNN part with LSTM\n",
    "rnn_input = Input(shape=(512,))  # Assuming this is the output shape from the CNN\n",
    "reshaped_rnn_input = Reshape((1, 512))(rnn_input)  # Reshape for LSTM compatibility\n",
    "rnn_output = LSTM(64)(reshaped_rnn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee61dd-f5d0-4fd9-94ff-5dbf86a39084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "# Combine both models\n",
    "combined_model = concatenate([cnn_output, rnn_output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca4528-e0d9-46f9-aa42-6a6c1343985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "output = Dense(num_classes, activation='softmax')(combined_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc792dd-b28e-4503-a115-7f77758d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined model\n",
    "model = Model(inputs=[densenet.input, rnn_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a1005-1a6c-4c63-8cc8-492eec1bf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aaae7b-902a-42fa-8fb4-0e72ee40a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 1\n",
    "stop_patience = 3\n",
    "factor = 0.5\n",
    "#tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"cnn_rnn_model.h5\", save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac29c7d-31f4-42b9-9aec-b869ff74ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "plot_model(model, to_file='cnn_rnn_plant.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13c26d-033b-423b-a929-407308e5b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_cnn, np.zeros((len(X_train_cnn), 512))], y_train_encoded, \n",
    "          validation_data=([X_val_cnn, np.zeros((len(X_val_cnn), 512))], y_val_encoded), \n",
    "          batch_size=64, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77029a53-932f-497e-86e2-0a0fc8b22d0c",
   "metadata": {},
   "source": [
    "#using rmsprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d8d70-872a-4a8c-af9f-b4c1b033387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined model\n",
    "model2 = Model(inputs=[densenet.input, rnn_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f4c76-e986-4ab0-9839-25a06b66bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac1d57-2836-4267-b403-2032922b0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 1\n",
    "stop_patience = 3\n",
    "factor = 0.5\n",
    "#tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"cnn_rnn_model_rmsprop.h5\", save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45089af1-f3c8-45da-bbe1-ecb82afcfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "plot_model(model2, to_file='cnn-rnn_rms_plant.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712972f7-e10c-45ca-97ea-a231686c7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model2.fit([X_train_cnn, np.zeros((len(X_train_cnn), 512))], y_train_encoded, \n",
    "          validation_data=([X_val_cnn, np.zeros((len(X_val_cnn), 512))], y_val_encoded), \n",
    "          batch_size=64, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19726806-2282-4468-a7b5-616215aa61eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fea28-ce38-4a53-b40c-554f4185a222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05472d-49e9-4f26-992d-001bea53eb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
